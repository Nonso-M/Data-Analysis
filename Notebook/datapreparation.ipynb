{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#columns\">Dropping Columns</a></li>\n",
    "<li><a href=\"#sql\">SQL Query</a></li>\n",
    "<li><a href=\"#eda\">Merging Dataframes </a></li>\n",
    "<li><a href=\"#eda2\">Merging Payment Dataframes </a></li>\n",
    "<li><a href=\"#eda3\">Merging Product Dataframes </a></li>\n",
    "<li><a href=\"#data\">Data Preprocessing</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "This Notebook aims to preprocess and analyse a transaction dataset contained in different sheets in a excel file linked by primary and secondary keys. These sheets includes\n",
    "- Orders\n",
    "- Orderedproducts\n",
    "- payments\n",
    "- ProductDetails\n",
    "- Reviews\n",
    "- Customers\n",
    "\n",
    "These Notebook are connected in the following ways (Through primary keys)\n",
    "- Orders-> OrderedProducts (order_id)\n",
    "- OrderedProducts-> Payments (order_id)\n",
    "- OrderedProduct-> ProductDetails (product_id)\n",
    "- Reviews-> Orders (order_id)\n",
    "- customers-> Orders (customer_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Loading the Dataframes from the excel file\n",
    "df_orders = pd.read_excel('../data/dataset for bizops.xlsx', sheet_name= 'Orders')\n",
    "df_orderprod = pd.read_excel('../data/dataset for bizops.xlsx', sheet_name= 'OrderedProducts')\n",
    "df_payment = pd.read_excel('../data/dataset for bizops.xlsx', sheet_name= 'Payments')\n",
    "df_prod_detail = pd.read_excel('../data/dataset for bizops.xlsx', sheet_name= 'Product Details')\n",
    "df_reviews = pd.read_excel('../data/dataset for bizops.xlsx', sheet_name= 'Reviews')\n",
    "df_customers = pd.read_excel('../data/dataset for bizops.xlsx', sheet_name= 'Customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='columns'></a>\n",
    "\n",
    "## Dropping Columns\n",
    "Some columns are not needed for this analysis and it is always advised to drop unimportant columns to reduce the memory being used during analysis. This makes the code cells run faster.\n",
    "The following cells would be dropped from the dataframes\n",
    "- __df_odd_detail__ -> ('product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g',\n",
    "                    'product_length_cm', 'product_height_cm', 'product_width_cm')\n",
    "\n",
    "- __df_reviews__ -> ('review_creation_date','review_answer_timestamp',review_id)\n",
    "- __df_customers__ -> ('customer_unique_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns in each dataframes\n",
    "\n",
    "df_prod_detail.drop(['product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g',\n",
    "                    'product_length_cm', 'product_height_cm', 'product_width_cm'],\n",
    "                     axis=1, inplace= True)\n",
    "\n",
    "\n",
    "df_customers.drop(['customer_unique_id'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "df_reviews.drop(['review_creation_date','review_answer_timestamp', 'review_id'], \n",
    "                axis=1, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Merging DataFrames \n",
    "All dataframs are combined into a single dataframe that is used for the final analysis. The dataframes are merged using their primary keys \n",
    "There will be two merged dataframes;\n",
    "- One for the product\n",
    "- One for the orders\n",
    "\n",
    "__Orders__ will be merged with reviews, payment and customer tables\n",
    "\n",
    "\n",
    "## Sql equivalent statement\n",
    "This merge can be done in sql using the following command\n",
    "```SQL\n",
    "select * from orders\n",
    "LEFT JOIN reviews ON orders.order_id = reviews.order_id\n",
    "LEFT JOIN payment ON orders.order_id = payment.order_id\n",
    "LEFT JOIN customer ON orders.order_id = customer.order_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sql'></a>\n",
    "## Sql equivalent statement\n",
    "This merge can be done in sql using the following command\n",
    "```SQL\n",
    "select * from orders\n",
    "LEFT JOIN reviews ON orders.order_id = reviews.order_id\n",
    "LEFT JOIN payment ON orders.order_id = payment.order_id\n",
    "LEFT JOIN customer ON orders.order_id = customer.order_id\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54011, 11)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging the data with the customers dataframe\n",
    "df_merge= df_orders.merge(df_customers, how='left', on= 'customer_id' )\n",
    "\n",
    "\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews dataframe contains duplicated rows, these rows will be dropped by using the _drop_duplicates__ method in pandas library\n",
    "- Removing duplicates ensures that new rows are not created when a join happens between two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'order_id', 'review_score', 'review_creation_date',\n",
       "       'review_answer_timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total rows in df_review_table is 56584\n",
      "The total number of duplicated columns is 144\n"
     ]
    }
   ],
   "source": [
    "print(f'The total rows in df_review_table is {df_reviews.shape[0]}')\n",
    "\n",
    "duplicates= df_reviews.duplicated(subset=['order_id', 'review_score']).sum()\n",
    "print(f'The total number of duplicated columns is {duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56355, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = df_reviews.drop_duplicates(subset= [\"order_id\"])\n",
    "df_reviews.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54011, 12)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_merge.merge(df_reviews, how= 'left',  on= 'order_id')\n",
    "\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda2'></a>\n",
    "## Merging the Payment Dataframe\n",
    "Some products were paid for over a certain period, so to get the the total payment we have to\n",
    "- Groupby the order_id\n",
    "- sum by the total payment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total rows in df_review_table is 54011\n",
      "The total number of duplicated columns is 0\n"
     ]
    }
   ],
   "source": [
    "print(f'The total rows in df_review_table is {df_payment.shape[0]}')\n",
    "\n",
    "duplicates= df_payment.duplicated(subset=['order_id']).sum()\n",
    "print(f'The total number of duplicated columns is {duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54011, 5)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_payment= df_payment.groupby('order_id').agg({'payment_sequential': 'first',\n",
    "                                    'payment_type': 'first',\n",
    "                                    'payment_installments': 'first',\n",
    "                                    'payment_value': \"sum\"\n",
    "                                    }).reset_index()\n",
    "\n",
    "\n",
    "df_payment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54011, 16)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_merge.merge(df_payment, how= 'left',  on= 'order_id')\n",
    "\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('../data/Order.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda3'></a>\n",
    "\n",
    "## Merging Product Dataframe\n",
    "This dataframe will consist of\n",
    "- Order Product\n",
    "- Product Table\n",
    "- Orders Table\n",
    "- Customer Table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
       "       'order_approved_at', 'order_delivered_carrier_date',\n",
       "       'order_delivered_customer_date', 'order_estimated_delivery_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61416, 11)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', \n",
    "        'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "\n",
    "df_prod_merge = df_orderprod.merge(df_orders[cols], how= 'left',  on= 'order_id')\n",
    "df_prod_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61416, 12)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging with Product table\n",
    "df_prod_merge = df_prod_merge.merge(df_prod_detail, how= 'left',  on= 'product_id')\n",
    "df_prod_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'order_item_id', 'product_id', 'seller_id', 'price',\n",
       "       'freight_value', 'customer_id', 'order_status',\n",
       "       'order_purchase_timestamp', 'order_delivered_customer_date',\n",
       "       'order_estimated_delivery_date', 'product_category_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prod_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'customer_zip_code_prefix', 'customer_city',\n",
       "       'customer_state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61416, 14)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging with customer table\n",
    "\n",
    "cols = ['customer_id',  'customer_city','customer_state']\n",
    "df_prod_merge = df_prod_merge.merge(df_customers[cols], how= 'left',  on= 'customer_id')\n",
    "\n",
    "df_prod_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_merge.to_csv('../data/Products.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## Data Preporocessing\n",
    "Here we will carry out some data preporocession like\n",
    "- Changing datetime columns todatetime objects\n",
    "- Changing state names to their full names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataframes\n",
    "df_pro = pd.read_csv('../data/Products.csv')\n",
    "df_od = pd.read_csv('../data/Orders.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61416 entries, 0 to 61415\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       61416 non-null  object        \n",
      " 1   order_item_id                  61416 non-null  int64         \n",
      " 2   product_id                     61416 non-null  object        \n",
      " 3   seller_id                      61416 non-null  object        \n",
      " 4   price                          61416 non-null  float64       \n",
      " 5   freight_value                  61416 non-null  float64       \n",
      " 6   customer_id                    61416 non-null  object        \n",
      " 7   order_status                   61416 non-null  object        \n",
      " 8   order_purchase_timestamp       61416 non-null  datetime64[ns]\n",
      " 9   order_delivered_customer_date  60319 non-null  datetime64[ns]\n",
      " 10  order_estimated_delivery_date  61416 non-null  datetime64[ns]\n",
      " 11  product_category_name          60732 non-null  object        \n",
      " 12  customer_city                  61416 non-null  object        \n",
      " 13  customer_state                 61416 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(2), int64(1), object(8)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "datetime_list = [ 'order_purchase_timestamp', 'order_delivered_customer_date',\n",
    "       'order_estimated_delivery_date']\n",
    "\n",
    "for x in datetime_list:\n",
    "    df_pro[x] = pd.to_datetime(df_pro[x])\n",
    "\n",
    "df_pro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date',\n",
    "       'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "\n",
    "for x in cols:\n",
    "    df_od[x] = pd.to_datetime(df_od[x])\n",
    "\n",
    "df_od.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting date and month from datetime columns in the Orders dataframe\n",
    "import calendar\n",
    "\n",
    "df_pro['order_month'] =df_pro['order_purchase_timestamp'].dt.month\n",
    "df_pro['order_month'] = df_pro['order_month'].apply(lambda x: calendar.month_name[x])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting date and month from datetime columns in the Product dataframe\n",
    "df_od['order_month'] =df_od['order_purchase_timestamp'].dt.month\n",
    "df_od['order_month'] = df_od['order_month'].apply(lambda x: calendar.month_name[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The states are abbreviated which causes ambiguity. A dataframe that contained the mappings between States codes and actual State name was downloaded from <a href=\"https://github.com/datasets-br/state-codes/blob/master/data/br-state-codes.csv\"> Dataframe Link</a>.\n",
    "\n",
    "This dataframe is used to map the State codes to the actual state names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                São Paulo\n",
       "1                São Paulo\n",
       "2                São Paulo\n",
       "3                São Paulo\n",
       "4                São Paulo\n",
       "               ...        \n",
       "53770         Minas Gerais\n",
       "53771       Rio de Janeiro\n",
       "53772       Rio de Janeiro\n",
       "53773    Rio Grande do Sul\n",
       "53774       Rio de Janeiro\n",
       "Name: customer_state, Length: 53775, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the downloaded dataframe and mappping the codes to the actual State name\n",
    "df_states = pd.read_csv('../data/br-state-codes.csv')\n",
    "\n",
    "df_od['customer_state']= df_od['customer_state'].map(df_states.set_index('subdivision')['name'])\n",
    "\n",
    "df_od['customer_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the same for the product Dataframe\n",
    "df_pro['customer_state']= df_pro['customer_state'].map(df_states.set_index('subdivision')['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Off the tables to Dataframes\n",
    "df_pro.to_csv('../data/Products.csv', index=False)\n",
    "df_od.to_csv('../data/Order.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7dcb4dd50af19b4a57bf6236270b1fac097ac28d4fb2716c7e6c0992ed9be23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
